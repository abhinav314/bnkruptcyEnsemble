{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import loadtxt\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import csv\n",
    "from scipy import stats\n",
    "# from sklearn.preprocessing import power_transform\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "from numpy import loadtxt\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn import metrics\n",
    "import csv\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import warnings\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import random\n",
    "\n",
    "# Plots\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Models\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor, BaggingRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.linear_model import Ridge, RidgeCV\n",
    "from sklearn.linear_model import ElasticNet, ElasticNetCV\n",
    "from sklearn.svm import SVR\n",
    "from mlxtend.regressor import StackingCVRegressor\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Stats\n",
    "from scipy.stats import skew, norm\n",
    "from scipy.special import boxcox1p\n",
    "from scipy.stats import boxcox_normmax\n",
    "\n",
    "# Misc\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Ignore useless warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\")\n",
    "pd.options.display.max_seq_items = 8000\n",
    "pd.options.display.max_rows = 8000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "\n",
    "# from imblearn.over_sampling import SMOTE, ADASYN\n",
    "# from collections import Counter\n",
    "# from sklearn.svm import LinearSVC\n",
    "\n",
    "dataset = pd.read_csv('C:/Purdue/Courses/Fall/Data Mining/Project/mgmt571/bankruptcy_Train.csv')\n",
    "dataset.drop_duplicates(keep = False, inplace = True)\n",
    "\n",
    "#dataset[(np.abs(stats.zscore(dataset)) < 3).all(axis=1)]\n",
    "\n",
    "\n",
    "# split data into train and test sets\n",
    "\n",
    "seed = 7\n",
    "\n",
    "# split data into X and y\n",
    "\n",
    "X = dataset[dataset.columns[0:64]]\n",
    "Y = pd.DataFrame(dataset[dataset.columns[64]])\n",
    "\n",
    "\n",
    "# interaction = PolynomialFeatures(degree=2, include_bias=False, interaction_only=True)\n",
    "# X = interaction.fit_transform(X)\n",
    "# X = pd.DataFrame(X)\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=1234)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "smote = SMOTE(ratio='minority')\n",
    "X_sm, y_sm = smote.fit_resample(X,Y)\n",
    "\n",
    "# X_sm_test, y_sm_test = smote.fit_resample(X_test,y_test)\n",
    "\n",
    "X_train = pd.DataFrame(X_sm)\n",
    "y_train = pd.DataFrame(y_sm)\n",
    "\n",
    "# X_test = pd.DataFrame(X_sm_test)\n",
    "# y_test = pd.DataFrame(y_sm_test)\n",
    "\n",
    "\n",
    "\n",
    "# # Create correlation matrix\n",
    "# corr_matrix = X.corr().abs()\n",
    "\n",
    "# # Select upper triangle of correlation matrix\n",
    "# upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "\n",
    "# # Find index of feature columns with correlation greater than 0.95\n",
    "# to_drop = [column for column in upper.columns if any(upper[column] > 0.80)]\n",
    "\n",
    "# # Drop features \n",
    "# X.drop(X[to_drop], axis=1, inplace = True)\n",
    "\n",
    "\n",
    "\n",
    "# interaction = PolynomialFeatures(degree=2, include_bias=False, interaction_only=True)\n",
    "# X = interaction.fit_transform(X)\n",
    "# X = pd.DataFrame(X)\n",
    "\n",
    "# pt = PowerTransformer()\n",
    "# pt.fit(X)                       ## Fit the PT on training data\n",
    "# X = pt.transform(X)## Then apply on all data\n",
    "# X=pd.DataFrame(X)\n",
    "\n",
    "\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.1, random_state=1234)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y = y_test\n",
    "train_labels = y_sm\n",
    "X = X_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=12, random_state=42, shuffle=True)\n",
    "\n",
    "# Define error metrics\n",
    "def rmsle(y, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y, y_pred))\n",
    "\n",
    "def cv_rmse(model, X= X):\n",
    "    rmse = np.sqrt(-cross_val_score(model, X, train_labels, scoring=\"neg_mean_squared_error\", cv=kf))\n",
    "    return (rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=12, random_state=42, shuffle=True)\n",
    "\n",
    "# Define error metrics\n",
    "def rmsle(y, y_pred):\n",
    "    return roc_auc_score(y, y_pred)\n",
    "\n",
    "def cv_rmse(model, X= X):\n",
    "    rmse = cross_val_score(model, X, train_labels, scoring=\"roc_auc\", cv=kf)\n",
    "    return (rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Light Gradient Boosting Regressor\n",
    "lightgbm = LGBMRegressor(objective='regression', \n",
    "                       num_leaves=6,\n",
    "                       learning_rate=0.01, \n",
    "                       n_estimators=7000,\n",
    "                       max_bin=200, \n",
    "                       bagging_fraction=0.8,\n",
    "                       bagging_freq=4, \n",
    "                       bagging_seed=8,\n",
    "                       feature_fraction=0.2,\n",
    "                       feature_fraction_seed=8,\n",
    "                       min_sum_hessian_in_leaf = 11,\n",
    "                       verbose=-1,\n",
    "                       random_state=42)\n",
    "\n",
    "# XGBoost Regressor\n",
    "xgboost = XGBRegressor(learning_rate=0.01,\n",
    "                       n_estimators=6000,\n",
    "                       max_depth=4,\n",
    "                       min_child_weight=0,\n",
    "                       gamma=0.6,\n",
    "                       subsample=0.7,\n",
    "                       colsample_bytree=0.7,\n",
    "                       objective='reg:linear',\n",
    "                       nthread=-1,\n",
    "                       scale_pos_weight=1,\n",
    "                       seed=27,\n",
    "                       reg_alpha=0.00006,\n",
    "                       random_state=42)\n",
    "\n",
    "# Ridge Regressor\n",
    "ridge_alphas = [1e-15, 1e-10, 1e-8, 9e-4, 7e-4, 5e-4, 3e-4, 1e-4, 1e-3, 5e-2, 1e-2, 0.1, 0.3, 1, 3, 5, 10, 15, 18, 20, 30, 50, 75, 100]\n",
    "ridge = make_pipeline(RobustScaler(), RidgeCV(alphas=ridge_alphas, cv=kf))\n",
    "\n",
    "# Support Vector Regressor\n",
    "svr = make_pipeline(RobustScaler(), SVR(C= 20, epsilon= 0.008, gamma=0.0003))\n",
    "\n",
    "# Gradient Boosting Regressor\n",
    "gbr = GradientBoostingRegressor(n_estimators=6000,\n",
    "                                learning_rate=0.01,\n",
    "                                max_depth=4,\n",
    "                                max_features='sqrt',\n",
    "                                min_samples_leaf=15,\n",
    "                                min_samples_split=10,\n",
    "                                loss='huber',\n",
    "                                random_state=42)  \n",
    "\n",
    "# Random Forest Regressor\n",
    "rf = RandomForestRegressor(n_estimators=1200,\n",
    "                          max_depth=15,\n",
    "                          min_samples_split=5,\n",
    "                          min_samples_leaf=5,\n",
    "                          max_features=None,\n",
    "                          oob_score=True,\n",
    "                          random_state=42)\n",
    "\n",
    "# Stack up all the models above, optimized using xgboost\n",
    "stack_gen = StackingCVRegressor(regressors=(xgboost, lightgbm, svr, ridge, gbr, rf),\n",
    "                                meta_regressor=xgboost,\n",
    "                                use_features_in_secondary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lightgbm: 0.9997 (0.0002)\n"
     ]
    }
   ],
   "source": [
    "scores = {}\n",
    "\n",
    "score = cv_rmse(lightgbm)\n",
    "print(\"lightgbm: {:.4f} ({:.4f})\".format(score.mean(), score.std()))\n",
    "scores['lgb'] = (score.mean(), score.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = cv_rmse(xgboost)\n",
    "print(\"xgboost: {:.4f} ({:.4f})\".format(score.mean(), score.std()))\n",
    "scores['xgb'] = (score.mean(), score.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = cv_rmse(svr)\n",
    "print(\"SVR: {:.4f} ({:.4f})\".format(score.mean(), score.std()))\n",
    "scores['svr'] = (score.mean(), score.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = cv_rmse(ridge)\n",
    "print(\"ridge: {:.4f} ({:.4f})\".format(score.mean(), score.std()))\n",
    "scores['ridge'] = (score.mean(), score.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = cv_rmse(rf)\n",
    "print(\"rf: {:.4f} ({:.4f})\".format(score.mean(), score.std()))\n",
    "scores['rf'] = (score.mean(), score.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = cv_rmse(gbr)\n",
    "print(\"gbr: {:.4f} ({:.4f})\".format(score.mean(), score.std()))\n",
    "scores['gbr'] = (score.mean(), score.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('stack_gen')\n",
    "stack_gen_model = stack_gen.fit(np.array(X), np.array(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('lightgbm')\n",
    "lgb_model_full_data = lightgbm.fit(X, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('xgboost')\n",
    "xgb_model_full_data = xgboost.fit(X, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Svr')\n",
    "svr_model_full_data = svr.fit(X, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Ridge')\n",
    "ridge_model_full_data = ridge.fit(X, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('RandomForest')\n",
    "rf_model_full_data = rf.fit(X, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('GradientBoosting')\n",
    "gbr_model_full_data = gbr.fit(X, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blend models in order to make the final predictions more robust to overfitting\n",
    "def blended_predictions(X):\n",
    "    return ((0.1 * ridge_model_full_data.predict(X)) + \\\n",
    "            (0.2 * svr_model_full_data.predict(X)) + \\\n",
    "            (0.1 * gbr_model_full_data.predict(X)) + \\\n",
    "            (0.1 * xgb_model_full_data.predict(X)) + \\\n",
    "            (0.1 * lgb_model_full_data.predict(X)) + \\\n",
    "            (0.05 * rf_model_full_data.predict(X)) + \\\n",
    "            (0.35 * stack_gen_model.predict(np.array(X))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get final precitions from the blended model\n",
    "blended_score = rmsle(train_labels, blended_predictions(X))\n",
    "scores['blended'] = (blended_score, 0)\n",
    "print('RMSLE score on train data:')\n",
    "print(blended_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the predictions for each model\n",
    "sns.set_style(\"white\")\n",
    "fig = plt.figure(figsize=(24, 12))\n",
    "\n",
    "ax = sns.pointplot(x=list(scores.keys()), y=[score for score, _ in scores.values()], markers=['o'], linestyles=['-'])\n",
    "for i, score in enumerate(scores.values()):\n",
    "    ax.text(i, score[0] + 0.002, '{:.6f}'.format(score[0]), horizontalalignment='left', size='large', color='black', weight='semibold')\n",
    "\n",
    "plt.ylabel('Score (RMSE)', size=20, labelpad=12.5)\n",
    "plt.xlabel('Model', size=20, labelpad=12.5)\n",
    "plt.tick_params(axis='x', labelsize=13.5)\n",
    "plt.tick_params(axis='y', labelsize=12.5)\n",
    "\n",
    "plt.title('Scores of Models', size=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rolig\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\rolig\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.864454\tvalidation_1-auc:0.847507\n",
      "[1]\tvalidation_0-auc:0.870859\tvalidation_1-auc:0.856278\n",
      "[2]\tvalidation_0-auc:0.875166\tvalidation_1-auc:0.85737\n",
      "[3]\tvalidation_0-auc:0.887984\tvalidation_1-auc:0.870018\n",
      "[4]\tvalidation_0-auc:0.887723\tvalidation_1-auc:0.869178\n",
      "[5]\tvalidation_0-auc:0.88862\tvalidation_1-auc:0.872159\n",
      "[6]\tvalidation_0-auc:0.905983\tvalidation_1-auc:0.889811\n",
      "[7]\tvalidation_0-auc:0.905692\tvalidation_1-auc:0.888846\n",
      "[8]\tvalidation_0-auc:0.908043\tvalidation_1-auc:0.89238\n",
      "[9]\tvalidation_0-auc:0.909052\tvalidation_1-auc:0.892349\n",
      "[10]\tvalidation_0-auc:0.909826\tvalidation_1-auc:0.892111\n",
      "[11]\tvalidation_0-auc:0.910062\tvalidation_1-auc:0.892981\n",
      "[12]\tvalidation_0-auc:0.913413\tvalidation_1-auc:0.897761\n",
      "[13]\tvalidation_0-auc:0.914047\tvalidation_1-auc:0.897877\n",
      "[14]\tvalidation_0-auc:0.914665\tvalidation_1-auc:0.899166\n",
      "[15]\tvalidation_0-auc:0.915476\tvalidation_1-auc:0.899468\n",
      "[16]\tvalidation_0-auc:0.915925\tvalidation_1-auc:0.899009\n",
      "[17]\tvalidation_0-auc:0.915619\tvalidation_1-auc:0.899522\n",
      "[18]\tvalidation_0-auc:0.915418\tvalidation_1-auc:0.899369\n",
      "[19]\tvalidation_0-auc:0.915526\tvalidation_1-auc:0.899657\n",
      "[20]\tvalidation_0-auc:0.915675\tvalidation_1-auc:0.899253\n",
      "[21]\tvalidation_0-auc:0.91616\tvalidation_1-auc:0.899607\n",
      "[22]\tvalidation_0-auc:0.931182\tvalidation_1-auc:0.911684\n",
      "[23]\tvalidation_0-auc:0.931621\tvalidation_1-auc:0.912478\n",
      "[24]\tvalidation_0-auc:0.933257\tvalidation_1-auc:0.914071\n",
      "[25]\tvalidation_0-auc:0.933459\tvalidation_1-auc:0.914654\n",
      "[26]\tvalidation_0-auc:0.934984\tvalidation_1-auc:0.917052\n",
      "[27]\tvalidation_0-auc:0.935954\tvalidation_1-auc:0.919388\n",
      "[28]\tvalidation_0-auc:0.936115\tvalidation_1-auc:0.919417\n",
      "[29]\tvalidation_0-auc:0.936617\tvalidation_1-auc:0.919093\n",
      "[30]\tvalidation_0-auc:0.937916\tvalidation_1-auc:0.918762\n",
      "[31]\tvalidation_0-auc:0.937813\tvalidation_1-auc:0.91838\n",
      "[32]\tvalidation_0-auc:0.938265\tvalidation_1-auc:0.918916\n",
      "[33]\tvalidation_0-auc:0.938265\tvalidation_1-auc:0.919045\n",
      "[34]\tvalidation_0-auc:0.938318\tvalidation_1-auc:0.918643\n",
      "[35]\tvalidation_0-auc:0.938662\tvalidation_1-auc:0.918562\n",
      "[36]\tvalidation_0-auc:0.939577\tvalidation_1-auc:0.918964\n",
      "[37]\tvalidation_0-auc:0.939719\tvalidation_1-auc:0.918847\n",
      "[38]\tvalidation_0-auc:0.940466\tvalidation_1-auc:0.91961\n",
      "[39]\tvalidation_0-auc:0.941039\tvalidation_1-auc:0.919574\n",
      "[40]\tvalidation_0-auc:0.941269\tvalidation_1-auc:0.920003\n",
      "[41]\tvalidation_0-auc:0.941419\tvalidation_1-auc:0.920802\n",
      "[42]\tvalidation_0-auc:0.941895\tvalidation_1-auc:0.921056\n",
      "[43]\tvalidation_0-auc:0.942071\tvalidation_1-auc:0.921757\n",
      "[44]\tvalidation_0-auc:0.9421\tvalidation_1-auc:0.921719\n",
      "[45]\tvalidation_0-auc:0.942785\tvalidation_1-auc:0.920378\n",
      "[46]\tvalidation_0-auc:0.943095\tvalidation_1-auc:0.920429\n",
      "[47]\tvalidation_0-auc:0.943299\tvalidation_1-auc:0.919501\n",
      "[48]\tvalidation_0-auc:0.943248\tvalidation_1-auc:0.919586\n",
      "[49]\tvalidation_0-auc:0.943638\tvalidation_1-auc:0.919977\n",
      "[50]\tvalidation_0-auc:0.94434\tvalidation_1-auc:0.920993\n",
      "[51]\tvalidation_0-auc:0.94447\tvalidation_1-auc:0.921665\n",
      "[52]\tvalidation_0-auc:0.94579\tvalidation_1-auc:0.921066\n",
      "[53]\tvalidation_0-auc:0.945816\tvalidation_1-auc:0.921137\n",
      "[54]\tvalidation_0-auc:0.946222\tvalidation_1-auc:0.922047\n",
      "[55]\tvalidation_0-auc:0.946388\tvalidation_1-auc:0.921783\n",
      "[56]\tvalidation_0-auc:0.946151\tvalidation_1-auc:0.921036\n",
      "[57]\tvalidation_0-auc:0.946089\tvalidation_1-auc:0.921243\n",
      "[58]\tvalidation_0-auc:0.945812\tvalidation_1-auc:0.921398\n",
      "[59]\tvalidation_0-auc:0.945814\tvalidation_1-auc:0.921911\n",
      "[60]\tvalidation_0-auc:0.946076\tvalidation_1-auc:0.921819\n",
      "[61]\tvalidation_0-auc:0.946368\tvalidation_1-auc:0.921462\n",
      "[62]\tvalidation_0-auc:0.946419\tvalidation_1-auc:0.921262\n",
      "[63]\tvalidation_0-auc:0.946661\tvalidation_1-auc:0.921979\n",
      "[64]\tvalidation_0-auc:0.946391\tvalidation_1-auc:0.922019\n",
      "[65]\tvalidation_0-auc:0.94733\tvalidation_1-auc:0.922198\n",
      "[66]\tvalidation_0-auc:0.947312\tvalidation_1-auc:0.92201\n",
      "[67]\tvalidation_0-auc:0.94732\tvalidation_1-auc:0.922018\n",
      "[68]\tvalidation_0-auc:0.947383\tvalidation_1-auc:0.921827\n",
      "[69]\tvalidation_0-auc:0.947663\tvalidation_1-auc:0.921896\n",
      "[70]\tvalidation_0-auc:0.94791\tvalidation_1-auc:0.921998\n",
      "[71]\tvalidation_0-auc:0.948017\tvalidation_1-auc:0.922168\n",
      "[72]\tvalidation_0-auc:0.948182\tvalidation_1-auc:0.922231\n",
      "[73]\tvalidation_0-auc:0.948359\tvalidation_1-auc:0.922119\n",
      "[74]\tvalidation_0-auc:0.948309\tvalidation_1-auc:0.92175\n",
      "[75]\tvalidation_0-auc:0.948662\tvalidation_1-auc:0.922435\n",
      "[76]\tvalidation_0-auc:0.948363\tvalidation_1-auc:0.922397\n",
      "[77]\tvalidation_0-auc:0.948351\tvalidation_1-auc:0.922437\n",
      "[78]\tvalidation_0-auc:0.948685\tvalidation_1-auc:0.922543\n",
      "[79]\tvalidation_0-auc:0.948626\tvalidation_1-auc:0.92265\n",
      "[80]\tvalidation_0-auc:0.94878\tvalidation_1-auc:0.922439\n",
      "[81]\tvalidation_0-auc:0.948786\tvalidation_1-auc:0.922767\n",
      "[82]\tvalidation_0-auc:0.949012\tvalidation_1-auc:0.923142\n",
      "[83]\tvalidation_0-auc:0.949273\tvalidation_1-auc:0.922775\n",
      "[84]\tvalidation_0-auc:0.949282\tvalidation_1-auc:0.922983\n",
      "[85]\tvalidation_0-auc:0.949619\tvalidation_1-auc:0.923741\n",
      "[86]\tvalidation_0-auc:0.949635\tvalidation_1-auc:0.923453\n",
      "[87]\tvalidation_0-auc:0.949647\tvalidation_1-auc:0.92333\n",
      "[88]\tvalidation_0-auc:0.950281\tvalidation_1-auc:0.924121\n",
      "[89]\tvalidation_0-auc:0.95009\tvalidation_1-auc:0.924051\n",
      "[90]\tvalidation_0-auc:0.950384\tvalidation_1-auc:0.924066\n",
      "[91]\tvalidation_0-auc:0.950465\tvalidation_1-auc:0.924625\n",
      "[92]\tvalidation_0-auc:0.950777\tvalidation_1-auc:0.924982\n",
      "[93]\tvalidation_0-auc:0.95085\tvalidation_1-auc:0.924857\n",
      "[94]\tvalidation_0-auc:0.950878\tvalidation_1-auc:0.925137\n",
      "[95]\tvalidation_0-auc:0.951303\tvalidation_1-auc:0.925261\n",
      "[96]\tvalidation_0-auc:0.95133\tvalidation_1-auc:0.924996\n",
      "[97]\tvalidation_0-auc:0.951285\tvalidation_1-auc:0.925031\n",
      "[98]\tvalidation_0-auc:0.951274\tvalidation_1-auc:0.924968\n",
      "[99]\tvalidation_0-auc:0.951437\tvalidation_1-auc:0.925618\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "              learning_rate=0.01, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
       "              nthread=None, objective='binary:logistic', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# smote = SMOTE(ratio='minority')\n",
    "# X_sm, y_sm = smote.fit_resample(X_train, y_train)\n",
    "# fit model no training data\n",
    "\n",
    "# model = RandomForestClassifier(n_estimators=10).fit(X_train, y_train)\n",
    "#X_test = X_test.as_matrix()\n",
    "# clf = XGBClassifier(max_depth= 6, learning_rate=0.1, n_estimators=1000,objective='binary:logistic',\n",
    "#                       min_child_weight = 8, feature_selector = 'greedy',reg_alpha= 0.005,\n",
    "#                       gamma=1, subsample=0.6, colsample_bytree=0.8)\n",
    "\n",
    "clf = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
    "              learning_rate=0.01, max_delta_step=0, max_depth=3,\n",
    "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
    "              nthread=None, objective='binary:logistic', random_state=0,\n",
    "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
    "              silent=None, subsample=1, verbosity=1)\n",
    "\n",
    "#clf = XGBClassifier()\n",
    "\n",
    "eval_set  = [(X_train, y_train), (X_test,y_test)]\n",
    "#clf.fit(X_sm, y_sm, eval_set=eval_set, eval_metric=\"auc\", early_stopping_rounds=30)\n",
    "\n",
    "#clf.fit(X_train, y_train, eval_set=eval_set, eval_metric=\"auc\" , early_stopping_rounds=30)\n",
    "\n",
    "clf.fit(X_train, y_train, eval_set=eval_set, eval_metric=\"auc\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " [[738 229]\n",
      " [ 99 868]]\n",
      "Accuracy: 83.04% \n",
      "\n",
      "0.8304033092037229\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "\n",
    "\n",
    "conf_mat = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "print('Confusion matrix:\\n', conf_mat)\n",
    "\n",
    "# evaluate predictions\n",
    "\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0),'\\n')\n",
    "\n",
    "print (roc_auc_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test dataset\n",
    "df_test = pd.read_csv('C:/Purdue/Courses/Fall/Data Mining/Project/mgmt571/bankruptcy_Test_X.csv')\n",
    "df_test=df_test.drop(['ID'],axis=1)\n",
    "# features = ['Attr1', 'Attr2', 'Attr3', 'Attr4', 'Attr5', 'Attr6', 'Attr8', 'Attr9',\n",
    "#        'Attr12', 'Attr13', 'Attr15', 'Attr16', 'Attr19', 'Attr20', 'Attr21',\n",
    "#        'Attr24', 'Attr27', 'Attr28', 'Attr29', 'Attr30', 'Attr32', 'Attr33',\n",
    "#        'Attr34', 'Attr36', 'Attr37', 'Attr38', 'Attr41', 'Attr45', 'Attr48',\n",
    "#        'Attr50', 'Attr53', 'Attr55', 'Attr57', 'Attr61']\n",
    "\n",
    "# df_test = df_test[features]\n",
    "df_test = df_test.as_matrix()\n",
    "pred = clf.predict_proba(df_test)\n",
    "test = pd.DataFrame (pred)\n",
    "\n",
    "test[1].to_csv('C:/Purdue/Courses/Fall/Data Mining/Project/mgmt571/result_r_latest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
